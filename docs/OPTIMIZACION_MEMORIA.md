# Gu√≠a de Optimizaci√≥n de Memoria - TableroGeneral

## Problema Identificado
El dashboard consume **9GB de RAM** y se queda en **7GB** en reposo. Esto es excesivo para un dashboard de Streamlit.

## Causas Principales

### 1. **Carga Completa de DataFrames**
- Se cargan TODAS las columnas de archivos Parquet
- No se usa lectura selectiva de columnas
- **Impacto**: ~60% del uso de RAM

### 2. **Duplicaci√≥n en Cach√© de Streamlit**
- `@st.cache_data` crea copias pickle
- TTL=1800s con max_entries=10 mantiene m√∫ltiples versiones
- **Impacto**: ~25% del uso de RAM

### 3. **Sin Liberaci√≥n de Memoria**
- No se llama a `gc.collect()` despu√©s de cargas
- Pandas mantiene referencias a DataFrames antiguos
- **Impacto**: ~10% del uso de RAM

### 4. **Conversi√≥n de Tipos Ineficiente**
- `convert_numpy_types()` crea copias innecesarias
- No se usa downcast de tipos num√©ricos
- **Impacto**: ~5% del uso de RAM

### 5. **GeoJSON Sin Simplificar**
- Geometr√≠as con alta resoluci√≥n innecesaria para visualizaci√≥n
- **Impacto**: Variable seg√∫n archivo

---

## Soluciones Implementadas

### ‚úÖ 1. M√≥dulo `carga_optimized.py`
Nuevo m√≥dulo con:
- **Lectura selectiva de columnas** en Parquet
- **Downcast autom√°tico** de tipos num√©ricos
- **Conversi√≥n a categor√≠as** para strings repetidos
- **Simplificaci√≥n de geometr√≠as** GeoJSON
- **Limpieza activa** con `gc.collect()`

### ‚úÖ 2. Funci√≥n `optimize_dataframe()`
Optimiza DataFrames:
```python
- int64 ‚Üí int8/int16/int32 (seg√∫n rango)
- float64 ‚Üí float32
- object ‚Üí category (si <50% valores √∫nicos)
- Elimina columnas totalmente nulas
```

### ‚úÖ 3. Funci√≥n `read_parquet_optimized()`
Mejora lectura:
```python
- columns par√°metro para leer solo necesarias
- strings_to_categorical=True autom√°tico
- self_destruct=True para liberar PyArrow
```

### ‚úÖ 4. Hash Personalizado para Cach√©
Evita duplicaci√≥n:
```python
hash_funcs={pd.DataFrame: lambda df: (df.shape, tuple(df.columns))}
```

### ‚úÖ 5. Funci√≥n `cleanup_memory()`
Limpieza autom√°tica cuando RAM > 70%

---

## C√≥mo Aplicar las Optimizaciones

### Paso 1: Identificar Columnas Necesarias

Ejecuta este script para analizar qu√© columnas usa cada m√≥dulo:

```python
python analizar_columnas_usadas.py
```

### Paso 2: Actualizar `COLUMNAS_NECESARIAS`

En `carga_optimized.py`, edita el diccionario con las columnas que realmente usas:

```python
COLUMNAS_NECESARIAS = {
    'df_postulantes_empleo.parquet': [
        'CUIL', 'EDAD', 'SEXO', 'PROVINCIA', 'DEPARTAMENTO',
        'FECHA_INSCRIPCION', 'ESTADO'
    ],
    # ... otros archivos
}
```

### Paso 3: Reemplazar Funciones de Carga

En `app.py`, cambia:

```python
# ANTES
from moduls.carga import load_data_from_local, load_data_from_gitlab

# DESPU√âS
from moduls.carga_optimized import (
    load_module_data_optimized,
    cleanup_memory
)
```

### Paso 4: Modificar Carga de M√≥dulos

En `app.py`, reemplaza `load_module_data()`:

```python
@st.cache_data(...)
def load_module_data(module_key):
    source_params = {
        'repo_id': REPO_ID,
        'branch': BRANCH,
        'token': gitlab_token,
        'local_path': LOCAL_PATH
    }

    source_type = 'gitlab' if FUENTE_DATOS == 'gitlab' else 'local'

    return load_module_data_optimized(
        module_key,
        source_type,
        source_params
    )
```

### Paso 5: Agregar Limpieza Peri√≥dica

Al final de `app.py`:

```python
# Limpiar memoria despu√©s de renderizar
from moduls.carga_optimized import cleanup_memory
cleanup_memory()
```

---

## Reducci√≥n Esperada de RAM

| Optimizaci√≥n | RAM Actual | RAM Optimizada | Reducci√≥n |
|--------------|------------|----------------|-----------|
| Lectura selectiva | ~5GB | ~1.5GB | **-70%** |
| Downcast tipos | ~1.5GB | ~0.8GB | **-47%** |
| Categor√≠as | ~0.8GB | ~0.5GB | **-38%** |
| Cach√© optimizado | ~1.5GB | ~0.3GB | **-80%** |
| GeoJSON simplificado | ~0.2GB | ~0.05GB | **-75%** |
| **TOTAL** | **~9GB** | **~2-3GB** | **-67% a -78%** |

---

## Mediciones y Monitoreo

### Script para medir uso actual:

```python
import psutil
import os

process = psutil.Process(os.getpid())
print(f"RAM usada: {process.memory_info().rss / 1024**3:.2f} GB")
print(f"% RAM: {process.memory_percent():.1f}%")
```

### Agregar al dashboard (modo desarrollo):

```python
if is_local:
    import psutil
    process = psutil.Process(os.getpid())
    st.sidebar.metric(
        "RAM Usada",
        f"{process.memory_info().rss / 1024**3:.2f} GB"
    )
```

---

## Pr√≥ximos Pasos

1. ‚úÖ Crear m√≥dulo `carga_optimized.py`
2. ‚è≥ Analizar columnas usadas por m√≥dulo
3. ‚è≥ Actualizar `COLUMNAS_NECESARIAS`
4. ‚è≥ Modificar `app.py` para usar carga optimizada
5. ‚è≥ Probar y medir mejoras
6. ‚è≥ Ajustar si es necesario

---

## Notas Importantes

‚ö†Ô∏è **Antes de aplicar en producci√≥n:**
- Prueba en local con datos reales
- Verifica que no se rompan visualizaciones
- Mide RAM antes y despu√©s
- Compara performance de carga

üí° **Tips adicionales:**
- Si sigue alto, considera lazy loading por pesta√±a
- Eval√∫a pre-agregar datos pesados
- Usa sampling para gr√°ficos con muchos puntos
